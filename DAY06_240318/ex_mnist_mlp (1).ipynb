{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 분류 <hr>\n",
    "- 데이터셋 : scikit-learn Fashion MNIST\n",
    "- 데이터수 : 학습용 60000, 테스틍용 10000\n",
    "- 피쳐갯수 : 28 X 28 흑백 이미지로 784\n",
    "- 타겟갯수 : 티셔츠/상의, 바지, 풀오버, 드레스, 코트, 샌들, 셔츠, 운동화, 가방, 발목 부츠 등 10가지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 모듈 로딩\n",
    "from sklearn.datasets import fetch_openml \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim \n",
    "import torchmetrics.functional as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 데이터 로딩 \n",
    "db_name = 'Fashion-MNIST'\n",
    "\n",
    "# as_frame=False : ndarray 형식으로 반환\n",
    "fashion_data = fetch_openml(name=db_name, parser='auto', as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data   => int64, (70000, 784)\n",
      "target => object, (70000,)\n",
      "feature_names => ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784']\n",
      "target_names => ['class']\n",
      "categories => {'class': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']}\n"
     ]
    }
   ],
   "source": [
    "### ===> 데이터 확인\n",
    "print(f'data   => {fashion_data[\"data\"].dtype}, {fashion_data[\"data\"].shape}')\n",
    "print(f'target => {fashion_data[\"target\"].dtype}, {fashion_data[\"target\"].shape}')\n",
    "print(f'feature_names => {fashion_data[\"feature_names\"]}\\ntarget_names => {fashion_data[\"target_names\"]}')\n",
    "print(f'categories => {fashion_data[\"categories\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 데이터 전처리 - 피쳐와 타겟 분리, 정규화 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature => <class 'numpy.ndarray'>, (70000, 784)\n",
      "feature raw data =>\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0\n",
      "    0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   36 136 127  62  54   0   0   0   1   3   4   0   0   3   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0\n",
      "    0   0   0  12  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15   0   0\n",
      "    0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163\n",
      "  127 121 122 146 141  88 172  66   0   0   0   0   0   0   0   0   0   1\n",
      "    1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243\n",
      "  202   0   0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212\n",
      "  218 192 169 227 208 218 224 212 226 197 209  52   0   0   0   0   0   0\n",
      "    0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220\n",
      "  245 119 167  56   0   0   0   0   0   0   0   0   0   4   0   0  55 236\n",
      "  228 230 228 240 232 213 218 223 234 217 217 209  92   0   0   0   1   4\n",
      "    6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223\n",
      "  229 215 218 255  77   0   0   3   0   0   0   0   0   0   0  62 145 204\n",
      "  228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0   0   0\n",
      "    0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234\n",
      "  176 188 250 248 233 238 215   0   0  57 187 208 224 221 224 208 204 214\n",
      "  208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0\n",
      "    3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0  98 233 198 210 222 229 229 234\n",
      "  249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224\n",
      "  229  29  75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195\n",
      "  227 245 239 223 218 212 209 222 220 221 230  67  48 203 183 194 213 197\n",
      "  185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172\n",
      "  181 205 206 115   0 122 219 193 179 171 183 196 204 210 213 207 211 210\n",
      "  200 196 194 191 195 191 198 192 176 156 167 177 210  92   0   0  74 189\n",
      "  212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188\n",
      "  188 194 192 216 170   0   2   0   0   0  66 200 222 237 239 242 246 243\n",
      "  244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0   0   0\n",
      "    0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "target  => <class 'numpy.ndarray'>,(70000,)\n",
      "target raw data  => ['9']\n"
     ]
    }
   ],
   "source": [
    "### ===> 피쳐와 타겟 분리\n",
    "# sklearn dataset 에서 이미 처리 해둠\n",
    "feature=fashion_data['data']\n",
    "target=fashion_data['target']\n",
    "\n",
    "print(f'feature => {type(feature)}, {feature.shape}')\n",
    "print(f'feature raw data =>\\n{feature[:1]}\\n')\n",
    "\n",
    "print(f'target  => {type(target)},{target.shape}')\n",
    "print(f'target raw data  => {target[:1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_feature =>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "norm_feature min => 0.0   max => 1.0\n"
     ]
    }
   ],
   "source": [
    "### ===> 정규화 : 피쳐\n",
    "# 이미지 데이터 값 0 ~ 255b\n",
    "norm_feature =feature/255.\n",
    "\n",
    "print(f'norm_feature =>\\n{norm_feature[:2]}')\n",
    "print(f'norm_feature min => {norm_feature.min()}   max => { norm_feature.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_target : int64 10개\n"
     ]
    }
   ],
   "source": [
    "### ===> 정규화 : 타겟\n",
    "# # 타겟 분류 클래스 : '0' ~ '9'  ==> 0 ~ 9 정수 변환\n",
    "norm_target=target.astype(int)\n",
    "print(f'norm_target : {norm_target.dtype} {np.unique(norm_target).size}개')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_target => (70000,), 1D\n",
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'norm_target => {norm_target.shape}, {norm_target.ndim}D\\n{norm_target[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 학습 데이터 셋 준비 - 훈련용, 검증용, 테스트용 데이터 셋 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3-1] 사용자 정의 데이터 셋 및 전체 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사용자정의 DataSet 클래스 \n",
    "# - 데이터의 Tensor 변환 \n",
    "class DLDataset(Dataset):\n",
    "    \n",
    "    # 초기화 함수 콜백함수(callback funcaion)\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        # ndarray ==> tensor\n",
    "        self.feature=torch.FloatTensor(x_data)\n",
    "        self.target=torch.LongTensor(y_data)\n",
    "        \n",
    "        \n",
    "    # 데이터셋의 갯수 체크 함수 콜백함수(callback funcaion)\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    \n",
    "    # 특정 인덱스 데이터+라벨 반환 콜백함수(callback funcaion)\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all dataset] feature : torch.Size([70000, 784]),   target : torch.Size([70000])\n"
     ]
    }
   ],
   "source": [
    "### 전체 데이터셋 생성\n",
    "##  DataSet 생성\n",
    "all_dataset = DLDataset(norm_feature, norm_target)\n",
    "\n",
    "print(f'[all dataset] feature : {all_dataset.feature.shape},   target : {all_dataset.target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3-2] 학습용, 검증용, 테스트용 데이터셋 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length    : 49000개\n",
      "Validation dataset      : 7000개\n",
      "Test dataset            : 14000개\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 고정 설정\n",
    "seed_gen=torch.Generator().manual_seed(42)\n",
    "\n",
    "TR_SIZE, VA_SIZE, TE_SIZE = 0.7, 0.1, 0.2\n",
    "\n",
    "trainDS, validDS, testDS = random_split(all_dataset, \n",
    "                                  [TR_SIZE, VA_SIZE, TE_SIZE], \n",
    "                                  generator=seed_gen)\n",
    "\n",
    "print(f\"Train dataset length    : {len(trainDS)}개\")\n",
    "print(f\"Validation dataset      : {len(validDS)}개\")\n",
    "print(f\"Test dataset            : {len(testDS)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터 로더 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "TRAIN_DL = DataLoader(trainDS, batch_size=BATCH_SIZE)\n",
    "VALID_DL = DataLoader(validDS, batch_size=BATCH_SIZE)\n",
    "TEST_DL = DataLoader(testDS,   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 모델 준비 : 입력층 입력 수, 출력층 출력 수 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 다중 분류 모델\n",
    "### ===> 입력층 피쳐 수  : 28 * 28\n",
    "### ===> 출력층 피쳐 수  : 10 (0 ~ 9)\n",
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    # 모델 구성 요소 초기화 \n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Linear(in_dim, 200)\n",
    "        self.layer2=nn.Linear(200, 100)\n",
    "        self.layer3=nn.Linear(100, 50)\n",
    "        self.layer4=nn.Linear(50, out_dim)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y=self.layer1(x)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer2(y)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer3(y)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer4(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 관련 함수 정의 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 진행함수 \n",
    "def training(epoch, model, optimizer, dataLoader, device, loss_fn, classes):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    model.train()\n",
    "    \n",
    "    # 배치크기 만큼 학습 진행 및 저장\n",
    "    train_report=[[], [], []]\n",
    "    for idx, (feature, target)  in enumerate(dataLoader):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        \n",
    "        # 학습\n",
    "        pre_traget = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = loss_fn(pre_traget, target)\n",
    "        train_report[0].append(loss)\n",
    "        \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "        train_report[2].append(f1)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not idx%50: print('.', end='')\n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(train_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(train_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(train_report[2])/BATCH_SIZE).item() \n",
    "    print(f'\\n[{epoch} Train ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 검증 및 테스트 진행함수 \n",
    "def testing(epoch, model, dataLoader, device, loss_fn, classes, kind='valid'):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼 학습 진행 및 저장\n",
    "        test_report=[[], [], []]\n",
    "        for idx, (feature, target)  in enumerate(dataLoader):\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # 학습\n",
    "            pre_traget = model(feature)\n",
    "\n",
    "            # 손실계산\n",
    "            loss = loss_fn(pre_traget, target)\n",
    "            test_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가 \n",
    "            acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "            test_report[1].append(acc)\n",
    "            \n",
    "            f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "            test_report[2].append(f1)\n",
    "            \n",
    "            #if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(test_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(test_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(test_report[2])/BATCH_SIZE).item() \n",
    "    print(f'[{epoch} {testing_type} ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}\\n')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전역변수 이용 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 입출력 피쳐\n",
    "IN_DIM , OUT_DIM = norm_feature.shape[1], np.unique(norm_target).size\n",
    "\n",
    "# 모델 인스턴스 \n",
    "MODEL = MNISTModel(IN_DIM, OUT_DIM).to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스 생성\n",
    "OPTIMIZER = optim.SGD(MODEL.parameters())\n",
    "\n",
    "#  손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 학습 횟수 설정\n",
    "EPOCHS=100\n",
    "\n",
    "# 분류 갯수\n",
    "CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 진행함수  - 전역변수 이용 시 \n",
    "def training(epoch):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    # model.train()\n",
    "    MODEL.train()\n",
    "    \n",
    "    # 배치크기 만큼 학습 진행 및 저장\n",
    "    train_report=[[], [], []]\n",
    "    for idx, (feature, target)  in enumerate(TRAIN_DL):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_traget = MODEL(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LOSS_FN(pre_traget, target)\n",
    "        train_report[0].append(loss)\n",
    "        \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "        train_report[2].append(f1)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        \n",
    "        # if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Vald' if kind == 'valid' else 'Test'\n",
    "\n",
    "    # 에포크 단위로 학습 모델 저장\n",
    "        \n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(train_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(train_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(train_report[2])/BATCH_SIZE).item() \n",
    "    print(f'\\n[{epoch} Train ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 검증 및 테스트 진행함수 \n",
    "def testing(epoch, kind='valid'):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    MODEL.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼 학습 진행 및 저장\n",
    "        test_report=[[], [], []]\n",
    "        dataloader = VALID_DL if kind=='valid' else TEST_DL\n",
    "        for idx, (feature, target)  in enumerate(TRAIN_DL):\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVIE)\n",
    "\n",
    "            # 학습\n",
    "            pre_traget = MODEL(feature)\n",
    "\n",
    "            # 손실계산\n",
    "            loss = LOSS_FN(pre_traget, target)\n",
    "            test_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가 \n",
    "            acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "            test_report[1].append(acc)\n",
    "            \n",
    "            f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "            test_report[2].append(f1)\n",
    "            \n",
    "            #if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(test_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(test_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(test_report[2])/BATCH_SIZE).item() \n",
    "    print(f'[{epoch} {testing_type} ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}\\n')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] 학습 : 학습 진행 준비, 학습 진행 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-1] 학습 진행 준비 :  모델, 최적화, 학습횟수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 입출력 피쳐\n",
    "IN_DIM , OUT_DIM = norm_feature.shape[1], np.unique(norm_target).size\n",
    "\n",
    "# 모델 인스턴스 \n",
    "MODEL = MNISTModel(IN_DIM, OUT_DIM).to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스 생성\n",
    "OPTIMIZER = optim.SGD(MODEL.parameters())\n",
    "\n",
    "#  손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 학습 횟수 설정\n",
    "EPOCHS=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-2] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100] "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "training() takes 1 positional argument but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepo\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     tr_score\u001b[38;5;241m=\u001b[39m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mOPTIMIZER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_DL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOSS_FN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUT_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     va_score\u001b[38;5;241m=\u001b[39mtesting(epo, MODEL, VALID_DL, DEVICE, LOSS_FN, OUT_DIM)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_):\n",
      "\u001b[0;31mTypeError\u001b[0m: training() takes 1 positional argument but 7 were given"
     ]
    }
   ],
   "source": [
    "train_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "val_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "for epo in range(EPOCHS):\n",
    "    print(f\"[Epoch {epo+1}/{EPOCHS}] \", end='')\n",
    "    tr_score=training(epo, MODEL,OPTIMIZER, TRAIN_DL, DEVICE, LOSS_FN, OUT_DIM)\n",
    "    va_score=testing(epo, MODEL, VALID_DL, DEVICE, LOSS_FN, OUT_DIM)\n",
    "    \n",
    "    for idx, key in enumerate(train_):\n",
    "        train_[key].append(tr_score[idx])\n",
    "        val_[key].append(va_score[idx])\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-3] 학습 후 평가 : Loss, Acc, F1 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  []\n",
      "acc  []\n",
      "f1  []\n"
     ]
    }
   ],
   "source": [
    "for idx, key in enumerate(train_):\n",
    "    print(f'{key} ', train_[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 테스트 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbCdEfG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39msplit:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39misupper():\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(s\u001b[38;5;241m.\u001b[39mlower,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
