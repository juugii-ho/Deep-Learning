{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 분류 <hr>\n",
    "- 데이터셋 : scikit-learn Fashion MNIST\n",
    "- 데이터수 : 학습용 60000, 테스틍용 10000\n",
    "- 피쳐갯수 : 28 X 28 흑백 이미지로 784\n",
    "- 타겟갯수 : 티셔츠/상의, 바지, 풀오버, 드레스, 코트, 샌들, 셔츠, 운동화, 가방, 발목 부츠 등 10가지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 모듈 로딩\n",
    "from sklearn.datasets import fetch_openml \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim \n",
    "import torchmetrics.functional as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 데이터 로딩 \n",
    "db_name = 'Fashion-MNIST'\n",
    "\n",
    "# as_frame=False : ndarray 형식으로 반환\n",
    "fashion_data = fetch_openml(name=db_name, parser='auto', as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data   => int64, (70000, 784)\n",
      "target => object, (70000,)\n",
      "feature_names => ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784']\n",
      "target_names => ['class']\n",
      "categories => {'class': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']}\n"
     ]
    }
   ],
   "source": [
    "### ===> 데이터 확인\n",
    "print(f'data   => {fashion_data[\"data\"].dtype}, {fashion_data[\"data\"].shape}')\n",
    "print(f'target => {fashion_data[\"target\"].dtype}, {fashion_data[\"target\"].shape}')\n",
    "print(f'feature_names => {fashion_data[\"feature_names\"]}\\ntarget_names => {fashion_data[\"target_names\"]}')\n",
    "print(f'categories => {fashion_data[\"categories\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 데이터 전처리 - 피쳐와 타겟 분리, 정규화 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature => <class 'numpy.ndarray'>, (70000, 784)\n",
      "feature raw data =>\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0\n",
      "    0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   36 136 127  62  54   0   0   0   1   3   4   0   0   3   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0\n",
      "    0   0   0  12  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15   0   0\n",
      "    0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163\n",
      "  127 121 122 146 141  88 172  66   0   0   0   0   0   0   0   0   0   1\n",
      "    1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243\n",
      "  202   0   0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212\n",
      "  218 192 169 227 208 218 224 212 226 197 209  52   0   0   0   0   0   0\n",
      "    0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220\n",
      "  245 119 167  56   0   0   0   0   0   0   0   0   0   4   0   0  55 236\n",
      "  228 230 228 240 232 213 218 223 234 217 217 209  92   0   0   0   1   4\n",
      "    6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223\n",
      "  229 215 218 255  77   0   0   3   0   0   0   0   0   0   0  62 145 204\n",
      "  228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0   0   0\n",
      "    0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234\n",
      "  176 188 250 248 233 238 215   0   0  57 187 208 224 221 224 208 204 214\n",
      "  208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0\n",
      "    3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0  98 233 198 210 222 229 229 234\n",
      "  249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224\n",
      "  229  29  75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195\n",
      "  227 245 239 223 218 212 209 222 220 221 230  67  48 203 183 194 213 197\n",
      "  185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172\n",
      "  181 205 206 115   0 122 219 193 179 171 183 196 204 210 213 207 211 210\n",
      "  200 196 194 191 195 191 198 192 176 156 167 177 210  92   0   0  74 189\n",
      "  212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188\n",
      "  188 194 192 216 170   0   2   0   0   0  66 200 222 237 239 242 246 243\n",
      "  244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0   0   0\n",
      "    0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "target  => <class 'numpy.ndarray'>,(70000,)\n",
      "target raw data  => ['9']\n"
     ]
    }
   ],
   "source": [
    "### ===> 피쳐와 타겟 분리\n",
    "# sklearn dataset 에서 이미 처리 해둠\n",
    "feature=fashion_data['data']\n",
    "target=fashion_data['target']\n",
    "\n",
    "print(f'feature => {type(feature)}, {feature.shape}')\n",
    "print(f'feature raw data =>\\n{feature[:1]}\\n')\n",
    "\n",
    "print(f'target  => {type(target)},{target.shape}')\n",
    "print(f'target raw data  => {target[:1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_feature =>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "norm_feature min => 0.0   max => 1.0\n"
     ]
    }
   ],
   "source": [
    "### ===> 정규화 : 피쳐\n",
    "# 이미지 데이터 값 0 ~ 255b\n",
    "norm_feature =feature/255.\n",
    "\n",
    "print(f'norm_feature =>\\n{norm_feature[:2]}')\n",
    "print(f'norm_feature min => {norm_feature.min()}   max => { norm_feature.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_target : int64 10개\n"
     ]
    }
   ],
   "source": [
    "### ===> 정규화 : 타겟\n",
    "# # 타겟 분류 클래스 : '0' ~ '9'  ==> 0 ~ 9 정수 변환\n",
    "norm_target=target.astype(int)\n",
    "print(f'norm_target : {norm_target.dtype} {np.unique(norm_target).size}개')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_target => (70000,), 1D\n",
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'norm_target => {norm_target.shape}, {norm_target.ndim}D\\n{norm_target[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 학습 데이터 셋 준비 - 훈련용, 검증용, 테스트용 데이터 셋 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3-1] 사용자 정의 데이터 셋 및 전체 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사용자정의 DataSet 클래스 \n",
    "# - 데이터의 Tensor 변환 \n",
    "class DLDataset(Dataset):\n",
    "    \n",
    "    # 초기화 함수 콜백함수(callback funcaion)\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        # ndarray ==> tensor\n",
    "        self.feature=torch.FloatTensor(x_data)\n",
    "        self.target=torch.LongTensor(y_data)\n",
    "        \n",
    "        \n",
    "    # 데이터셋의 갯수 체크 함수 콜백함수(callback funcaion)\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    \n",
    "    # 특정 인덱스 데이터+라벨 반환 콜백함수(callback funcaion)\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all dataset] feature : torch.Size([70000, 784]),   target : torch.Size([70000])\n"
     ]
    }
   ],
   "source": [
    "### 전체 데이터셋 생성\n",
    "##  DataSet 생성\n",
    "all_dataset = DLDataset(norm_feature, norm_target)\n",
    "\n",
    "print(f'[all dataset] feature : {all_dataset.feature.shape},   target : {all_dataset.target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3-2] 학습용, 검증용, 테스트용 데이터셋 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length    : 49000개\n",
      "Validation dataset      : 7000개\n",
      "Test dataset            : 14000개\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 고정 설정\n",
    "seed_gen=torch.Generator().manual_seed(42)\n",
    "\n",
    "TR_SIZE, VA_SIZE, TE_SIZE = 0.7, 0.1, 0.2\n",
    "\n",
    "trainDS, validDS, testDS = random_split(all_dataset, \n",
    "                                  [TR_SIZE, VA_SIZE, TE_SIZE], \n",
    "                                  generator=seed_gen)\n",
    "\n",
    "print(f\"Train dataset length    : {len(trainDS)}개\")\n",
    "print(f\"Validation dataset      : {len(validDS)}개\")\n",
    "print(f\"Test dataset            : {len(testDS)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터 로더 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "TRAIN_DL = DataLoader(trainDS, batch_size=BATCH_SIZE)\n",
    "VALID_DL = DataLoader(validDS, batch_size=BATCH_SIZE)\n",
    "TEST_DL = DataLoader(testDS,   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 모델 준비 : 입력층 입력 수, 출력층 출력 수 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 다중 분류 모델\n",
    "### ===> 입력층 피쳐 수  : 28 * 28\n",
    "### ===> 출력층 피쳐 수  : 10 (0 ~ 9)\n",
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    # 모델 구성 요소 초기화 \n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Linear(in_dim, 200)\n",
    "        self.layer2=nn.Linear(200, 100)\n",
    "        self.layer3=nn.Linear(100, 50)\n",
    "        self.layer4=nn.Linear(50, out_dim)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y=self.layer1(x)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer2(y)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer3(y)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer4(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ==> 다중 분류 모델\n",
    "### ==> 입력층 피쳐 수 : 28*28\n",
    "### ==> 은닉층 갯수, 피쳐 수 : 동적 \n",
    "### ==> 출력층 피쳐 수 : 10 (0~9)\n",
    "\n",
    "# feature = [[0 for col in range(28)] for col in range(28)]\n",
    "# feature = np.array(feature)\n",
    "# # feature = torch.\n",
    "# print(feature)\n",
    "\n",
    "class MNISTModel_28(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(in_dim, int(in_dim / 2))\n",
    "        self.hidden_layer = []\n",
    "        percep = int(in_dim / 2)\n",
    "        while percep > 50:\n",
    "            self.hidden_layer.append(nn.Linear(percep, int(percep / 2)))\n",
    "            percep = int(percep / 2)\n",
    "        self.output_layer = nn.Linear(percep, out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        for hl in self.hidden_layer:\n",
    "            x = hl(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 관련 함수 정의 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6-1] 매개변수 이용 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 진행함수 \n",
    "def training(epoch, model, optimizer, dataLoader, device, loss_fn, classes):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    model.train()\n",
    "    \n",
    "    # 배치크기 만큼 학습 진행 및 저장\n",
    "    train_report=[[], [], []]\n",
    "    for idx, (feature, target)  in enumerate(dataLoader):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        \n",
    "        # 학습\n",
    "        pre_traget = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = loss_fn(pre_traget, target)\n",
    "        train_report[0].append(loss)\n",
    "        \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "        train_report[2].append(f1)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not idx%50: print('.', end='')\n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(train_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(train_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(train_report[2])/BATCH_SIZE).item() \n",
    "    print(f'\\n[{epoch} Train ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 검증 및 테스트 진행함수 \n",
    "def testing(epoch, model, dataLoader, device, loss_fn, classes, kind='valid'):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼 학습 진행 및 저장\n",
    "        test_report=[[], [], []]\n",
    "        for idx, (feature, target)  in enumerate(dataLoader):\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # 학습\n",
    "            pre_traget = model(feature)\n",
    "\n",
    "            # 손실계산\n",
    "            loss = loss_fn(pre_traget, target)\n",
    "            test_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가 \n",
    "            acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "            test_report[1].append(acc)\n",
    "            \n",
    "            f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "            test_report[2].append(f1)\n",
    "            \n",
    "            #if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(test_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(test_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(test_report[2])/BATCH_SIZE).item() \n",
    "    print(f'[{epoch} {testing_type} ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}\\n')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6-2] 전역변수 이용 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 입출력 피쳐\n",
    "IN_DIM , OUT_DIM = norm_feature.shape[1], np.unique(norm_target).size\n",
    "\n",
    "# 모델 인스턴스 \n",
    "MODEL = MNISTModel_28(IN_DIM, OUT_DIM).to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스 생성\n",
    "OPTIMIZER = optim.SGD(MODEL.parameters())\n",
    "\n",
    "#  손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 학습 횟수 설정\n",
    "EPOCHS=3\n",
    "\n",
    "# 분류 갯수\n",
    "CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 진행함수  - 전역변수 이용 시 \n",
    "def training(epoch, kind='valid'):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    # model.train()\n",
    "    MODEL.train()\n",
    "    \n",
    "    # 배치크기 만큼 학습 진행 및 저장\n",
    "    train_report=[[], [], []]\n",
    "    for idx, (feature, target)  in enumerate(TRAIN_DL):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 학습\n",
    "        pre_traget = MODEL(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = LOSS_FN(pre_traget, target)\n",
    "        train_report[0].append(loss)\n",
    "        \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "        train_report[2].append(f1)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        \n",
    "        # if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "\n",
    "    # 에포크 단위로 학습 모델 저장\n",
    "        \n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(train_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(train_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(train_report[2])/BATCH_SIZE).item() \n",
    "    print(f'\\n[{epoch} Train ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 검증 및 테스트 진행함수 \n",
    "def testing(epoch, kind='valid'):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    MODEL.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼 학습 진행 및 저장\n",
    "        test_report=[[], [], []]\n",
    "        dataloader = VALID_DL if kind=='valid' else TEST_DL\n",
    "        for idx, (feature, target)  in enumerate(TRAIN_DL):\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            # 학습\n",
    "            pre_traget = MODEL(feature)\n",
    "\n",
    "            # 손실계산\n",
    "            loss = LOSS_FN(pre_traget, target)\n",
    "            test_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가 \n",
    "            acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "            test_report[1].append(acc)\n",
    "            \n",
    "            f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=CLASSES)\n",
    "            test_report[2].append(f1)\n",
    "            \n",
    "            #if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(test_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(test_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(test_report[2])/BATCH_SIZE).item() \n",
    "    print(f'[{epoch} {testing_type} ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}\\n')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] 학습 : 학습 진행 준비, 학습 진행 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-1] 학습 진행 준비 :  모델, 최적화, 학습횟수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 입출력 피쳐\n",
    "IN_DIM , OUT_DIM = norm_feature.shape[1], np.unique(norm_target).size\n",
    "\n",
    "# 모델 인스턴스 \n",
    "MODEL = MNISTModel_28(IN_DIM, OUT_DIM).to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스 생성\n",
    "OPTIMIZER = optim.SGD(MODEL.parameters())\n",
    "\n",
    "#  손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 학습 횟수 설정\n",
    "EPOCHS=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-2] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## 학습 중 모델 저장관련 변수\n",
    "dir = '../data/model/'\n",
    "filename = dir+'best_model28.pth'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(dir): # mkdir : 바로 상위의 폴더가 없을 경우만 만들어줌\n",
    "    # os.mkdir(dir)            # ㄴ 하위 폴더만 생성 즉, data 폴더는 이미 존재해야 함!\n",
    "    os.makedirs(dir)        # 해당 디렉토리로 갈 때 없는 폴더 다 만듦\n",
    "    print('1')\n",
    "print(os.path.exists(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 Train ] Loss ==> 45.155 Acc ==> 1.971 F1 ==> 1.971\n",
      "[0 Valid ] Loss ==> 45.119 Acc ==> 1.971 F1 ==> 1.971\n",
      "\n",
      "[Epoch 2/3] \n",
      "[1 Train ] Loss ==> 45.086 Acc ==> 1.971 F1 ==> 1.971\n",
      "[1 Valid ] Loss ==> 45.054 Acc ==> 1.971 F1 ==> 1.971\n",
      "\n",
      "[Epoch 3/3] \n",
      "[2 Train ] Loss ==> 45.024 Acc ==> 1.971 F1 ==> 1.971\n",
      "[2 Valid ] Loss ==> 44.993 Acc ==> 1.971 F1 ==> 1.971\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 데이터 히스토리 저장 - 시각화 위해서\n",
    "train_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "val_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "\n",
    "# 모델 저장 관련 변수\n",
    "pre_va_score = 100\n",
    "\n",
    "\n",
    "# 학습 진행\n",
    "for epo in range(EPOCHS):\n",
    "    print(f\"[Epoch {epo+1}/{EPOCHS}] \", end='')\n",
    "\n",
    "    tr_score=training(epo)\n",
    "    va_score=testing(epo)\n",
    "    \n",
    "    # 검증 데이터 기준 학습된 모델 저장 ==> Loss가 이전보다 작아진 경우 저장 / Acc 또느 F1이면 이전보다 큰 경우 저장\n",
    "    if pre_va_score > va_score[0] :     # Loss 기준\n",
    "        torch.save(MODEL, filename)     # 모델 저장\n",
    "        # torch.state_dict(MODEL, filename)     # 매개변수 저장\n",
    "\n",
    "\n",
    "    for idx, key in enumerate(train_):\n",
    "        train_[key].append(tr_score[idx])\n",
    "        val_[key].append(va_score[idx])\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-3] 학습 후 평가 : Loss, Acc, F1 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  [45.1552734375, 45.086238861083984, 45.023624420166016]\n",
      "acc  [1.9708033800125122, 1.9708033800125122, 1.9708033800125122]\n",
      "f1  [1.9708033800125122, 1.9708033800125122, 1.9708033800125122]\n"
     ]
    }
   ],
   "source": [
    "for idx, key in enumerate(train_):\n",
    "    print(f'{key} ', train_[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 테스트 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Axes object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Loss와 Acc F1 시각화\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable Axes object"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Loss와 Acc F1 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (layer1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (layer2): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (layer3): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (layer4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로딩\n",
    "torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm1\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "m1 = '../data/data/o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm2\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm2' is not defined"
     ]
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
