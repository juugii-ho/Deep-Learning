{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # 모델 구성 요소 생성 및 구조 설정 (보통 init은 인스턴스 생성, 추가)\n",
    "    def __init__(self):                         \n",
    "        super(Net,self).__init__()      # super().__init__()로 생략 가능\n",
    "        self.fc1 = nn.Linear(8,4)       # 레이어 이름 변수명이 중요\n",
    "        self.fc2 = nn.Linear(4,2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(2,1)\n",
    "\n",
    "    # 순방향 학습 진행 함수\n",
    "    def forward(self,x):\n",
    "        return self.fc3(self.fc2(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### 모델 인스턴스 생성\n",
    "model = Net()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=4, bias=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 인스턴스 속성 확인\n",
    "# 모델의 특정 층 추출\n",
    "model.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.1831,  0.3359,  0.1547,  0.1539,  0.2978,  0.3525,  0.1048, -0.2427],\n",
       "         [-0.2636,  0.3162,  0.1765, -0.2295,  0.0360, -0.1654,  0.1894,  0.0241],\n",
       "         [-0.2957, -0.2359,  0.2298,  0.3100,  0.1567, -0.0491,  0.1817,  0.1657],\n",
       "         [-0.0491, -0.3448,  0.0442,  0.3359, -0.2834,  0.3460,  0.1271,  0.2247]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2253,  0.0677,  0.2431, -0.0352], requires_grad=True))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 인스턴스 속성 확인\n",
    "# 모델의 특정 층 추출\n",
    "model.fc1.weight, model.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x13adce6d0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1831,  0.3359,  0.1547,  0.1539,  0.2978,  0.3525,  0.1048, -0.2427],\n",
      "        [-0.2636,  0.3162,  0.1765, -0.2295,  0.0360, -0.1654,  0.1894,  0.0241],\n",
      "        [-0.2957, -0.2359,  0.2298,  0.3100,  0.1567, -0.0491,  0.1817,  0.1657],\n",
      "        [-0.0491, -0.3448,  0.0442,  0.3359, -0.2834,  0.3460,  0.1271,  0.2247]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.2253,  0.0677,  0.2431, -0.0352], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[ 0.0148, -0.0257, -0.1827, -0.4351],\n",
      "        [ 0.3956,  0.4034, -0.2282, -0.0105]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0.4659, 0.2439], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.1136, 0.5879]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.4809], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델의 각 층별 w, b 텐서 정보 확인\n",
    "for m in model.parameters():\n",
    "    print(m, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fc1.weight', Parameter containing:\n",
      "tensor([[-0.1831,  0.3359,  0.1547,  0.1539,  0.2978,  0.3525,  0.1048, -0.2427],\n",
      "        [-0.2636,  0.3162,  0.1765, -0.2295,  0.0360, -0.1654,  0.1894,  0.0241],\n",
      "        [-0.2957, -0.2359,  0.2298,  0.3100,  0.1567, -0.0491,  0.1817,  0.1657],\n",
      "        [-0.0491, -0.3448,  0.0442,  0.3359, -0.2834,  0.3460,  0.1271,  0.2247]],\n",
      "       requires_grad=True))\n",
      "\n",
      "('fc1.bias', Parameter containing:\n",
      "tensor([-0.2253,  0.0677,  0.2431, -0.0352], requires_grad=True))\n",
      "\n",
      "('fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0148, -0.0257, -0.1827, -0.4351],\n",
      "        [ 0.3956,  0.4034, -0.2282, -0.0105]], requires_grad=True))\n",
      "\n",
      "('fc2.bias', Parameter containing:\n",
      "tensor([0.4659, 0.2439], requires_grad=True))\n",
      "\n",
      "('fc3.weight', Parameter containing:\n",
      "tensor([[0.1136, 0.5879]], requires_grad=True))\n",
      "\n",
      "('fc3.bias', Parameter containing:\n",
      "tensor([-0.4809], requires_grad=True))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델의 각 층별 w, b 텐서 정보 확인 + 이름 포함\n",
    "for m in model.named_parameters():\n",
    "    print(m, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer의 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4549,  0.0774, -0.3603, -0.7001, -0.2724,  0.7017, -0.5751,  0.2083],\n",
       "        [ 0.3311, -0.2439, -0.6362, -0.5138, -0.1863, -0.2128, -0.4619, -0.4450],\n",
       "        [-0.6114, -0.6620,  0.7016,  0.6546,  0.3998, -0.5668,  0.3344,  0.0197],\n",
       "        [-0.4307, -0.2502, -0.0700, -0.3887, -0.6610,  0.1265, -0.4456,  0.0408]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세비어 알고리즘의 가중치 초기화 - S자 모형에서 좋음\n",
    "\n",
    "nn.init.xavier_uniform_(model.fc1.weight)   # _ : inplace = True 의미(저장됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4549,  0.0774, -0.3603, -0.7001, -0.2724,  0.7017, -0.5751,  0.2083],\n",
       "        [ 0.3311, -0.2439, -0.6362, -0.5138, -0.1863, -0.2128, -0.4619, -0.4450],\n",
       "        [-0.6114, -0.6620,  0.7016,  0.6546,  0.3998, -0.5668,  0.3344,  0.0197],\n",
       "        [-0.4307, -0.2502, -0.0700, -0.3887, -0.6610,  0.1265, -0.4456,  0.0408]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9y/lpn0hjmn5csct06t4_r5qtjr0000gn/T/ipykernel_46686/872923808.py:2: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(child.weight)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dropout' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[0;32m----> 2\u001b[0m     nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform(\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch_PY38/lib/python3.8/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dropout' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for name, child in model.named_children():\n",
    "    nn.init.xavier_uniform(child.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "\n",
      "Linear(in_features=4, out_features=2, bias=True)\n",
      "\n",
      "Dropout(p=0.5, inplace=False)\n",
      "\n",
      "Linear(in_features=2, out_features=1, bias=True)\n",
      "\n",
      "('fc1', Linear(in_features=8, out_features=4, bias=True))\n",
      "\n",
      "('fc2', Linear(in_features=4, out_features=2, bias=True))\n",
      "\n",
      "('drop', Dropout(p=0.5, inplace=False))\n",
      "\n",
      "('fc3', Linear(in_features=2, out_features=1, bias=True))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 모든 Layer 가져오기\n",
    "for child in model.children():\n",
    "    print(child, end='\\n\\n')\n",
    "\n",
    "\n",
    "# 모델 구성 모든 Layer 이름까지 가져오기\n",
    "for child in model.named_children():\n",
    "    print(child, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0399, -0.2192, -0.1094, -0.2222],\n",
       "        [ 1.6710,  1.2754, -0.5390, -0.7937]], requires_grad=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 헤 알고리즘의 가중치 초기화 (keras에는 he임)\n",
    "nn.init.kaiming_normal_(model.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Linear: 1-1                            36\n",
       "├─Linear: 1-2                            10\n",
       "├─Dropout: 1-3                           --\n",
       "├─Linear: 1-4                            3\n",
       "=================================================================\n",
       "Total params: 49\n",
       "Trainable params: 49\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)\n",
    "#  ( w 8개 x b 1개 ) x feature 4개 = 36\n",
    "#  ( w 4개 x b 1개 ) x feature 2개 = 10\n",
    "#  ( w 2개 x b 1개)  x feature 1개 =  3\n",
    "# 총합 49개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
